# Transfer Learning Wildlife

# Project Background
Deep learning models have revolutionized the science of computer vision, with applications ranging from facial recognition, biomedical image processing, and self-driving cars (Voulodimos, Doulamis, Doulamis, & Protopapadakis, 2018). However, an area that has received relatively little attention is wildlife conservation. National scale wildlife conservation programs rely on motion-sensor cameras to collect imagery in remote wilderness regions. These images provide researchers with up-to-date information on the behaviour, distribution and abundance of wildlife. Given the large volume of imagery collected (thousands to millions), it is not feasible for experts or volunteers to manually review them. As such, there is a pressing need to adopt automated computer vision recognition to support this image review process.
The Manaaki Whenua Landcare Research (https://www.landcareresearch.co.nz) is seeking to build a national wildlife monitoring system that benefits from this computer vision technology. Manaaki Whenua Landcare Research is a pioneering conservation and research organisation, receiving support from GroundTruth (https://www.groundtruth.co.nz), World Wildlife Fund NZ (https://www.wwf.org.nz), and the New Zealand government directly. The envisioned system is to comprise a machine learning equipped web service that automatically labels wildlife imagery, which can be easily accessed and shared between a network of authorised community, private and government end users. This information will ultimately serve to guide and inform future conservation efforts.

# Aims
To support this endeavour, this project aimed to comprehensively investigate, evaluate, and report on deep learning-based models for the recognition of New Zealand camera trap species. While there exists a number of models to identify wildlife, few have been trained specifically on camera trap imagery, which can often be of poor quality (e.g. blurry, partial views of animals). Fewer still have been built to effectively integrate with client-side machine learning and its associated constraints. This project addresses this need by providing a detailed understanding of the effectiveness of deep learning models for the recognition of camera trap species. Findings shed light on practical constraints, such as model storage size and prediction latency, to inform and guide back-end software development.

# Method
A total of 76 different models were exploration and fine-tuned over a 7-week period from the 10th August 2019 to the 2nd of October 2019. When evaluating the performance of a model, two key metrics to considered were the overall classification accuracy across the all the classes, as well as the classification accuracy for individual classes. Model parameters investigated were 1) the choice of number of “trainable” model layers; 2) optimizer (Adam, Stochastic Gradient Descent, RMSProp, and Adadelta); 3) learning rate; 4) image augmentation strategies (rotations, zooms, sheers, and horizontal flips); 5) weight decay; 6) batch size; and 7) number of epochs.

# Results
The model has been trained to predict 7 animal classes (bird, cat, hedgehog, leporidae, possum, rodent, other), and 1 non-animal class (nothing here / unclassifiable) captured by camera trap imagery. As such, the model is intended to be used in wildlife environments inhabited with these species. The overall classification accuracy was 79.7% on a test set; whether this is considered acceptable will depend on the specific application. The model is particularly strong in identifying cat, possum, and other, but weaker in identifying rodent and nothing here / unclassifiable. For instance, the model predicted bird and rodent in images where no recognisable animal was present. It is possible that these images contained combinations of features such as odd-shaped rocks and branches that were misclassified as these animals.

# Conclusion
Future work could improve model performance in a number of ways. Firstly, researchers should focus on improving recognition of the non-animal class (nothing here, unclassifiable), as this class was the main source of model misclassification. To this end, one could evaluate the merit of a two-stage classifier that first detects whether or not an animal is present before identifying the actual animal class. Secondly, good image quality should be used in preference to large amounts of poor image quality, as the former proved crucial in producing the best model performance. It would also be beneficial to train on larger datasets containing a broader variety of animal classes.
